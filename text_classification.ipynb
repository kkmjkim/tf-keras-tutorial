{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic4_occAAiAT"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ioaprt5q5US7"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yCl0eTNH5RS3"
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItXfxkxvosLH"
      },
      "source": [
        "# 영화 리뷰를 사용한 텍스트 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKY4XMc9o8iB"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />TensorFlow.org에서 보기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />깃허브(GitHub) 소스 보기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMrWLbtWaZWE"
      },
      "source": [
        "Note: 이 문서는 텐서플로 커뮤니티에서 번역했습니다. 커뮤니티 번역 활동의 특성상 정확한 번역과 최신 내용을 반영하기 위해 노력함에도\n",
        "불구하고 [공식 영문 문서](https://www.tensorflow.org/?hl=en)의 내용과 일치하지 않을 수 있습니다.\n",
        "이 번역에 개선할 부분이 있다면\n",
        "[tensorflow/docs-l10n](https://github.com/tensorflow/docs-l10n/) 깃헙 저장소로 풀 리퀘스트를 보내주시기 바랍니다.\n",
        "문서 번역이나 리뷰에 참여하려면\n",
        "[docs-ko@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ko)로\n",
        "메일을 보내주시기 바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg62Pmz3o83v"
      },
      "source": [
        "이 노트북은 영화 리뷰(review) 텍스트를 *긍정*(positive) 또는 *부정*(negative)으로 분류합니다. 이 예제는 *이진*(binary)-또는 클래스(class)가 두 개인- 분류 문제입니다. 이진 분류는 머신러닝에서 중요하고 널리 사용됩니다.\n",
        "\n",
        "여기에서는 [인터넷 영화 데이터베이스](https://www.imdb.com/)(Internet Movie Database)에서 수집한 50,000개의 영화 리뷰 텍스트를 담은 [IMDB 데이터셋](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb)을 사용하겠습니다. 25,000개 리뷰는 훈련용으로, 25,000개는 테스트용으로 나뉘어져 있습니다. 훈련 세트와 테스트 세트의 클래스는 *균형*이 잡혀 있습니다. 즉 긍정적인 리뷰와 부정적인 리뷰의 개수가 동일합니다.\n",
        "\n",
        "이 노트북은 모델을 만들고 훈련하기 위해 텐서플로의 고수준 파이썬 API인 [tf.keras](https://www.tensorflow.org/guide/keras)를 사용합니다. `tf.keras`를 사용한 고급 텍스트 분류 튜토리얼은 [MLCC 텍스트 분류 가이드](https://developers.google.com/machine-learning/guides/text-classification/)를 참고하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ew7HTbPpCJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34208d66-58e3-40e4-c5d6-b986cf501df8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsKG535pHep"
      },
      "source": [
        "## IMDB 데이터셋 다운로드\n",
        "\n",
        "IMDB 데이터셋은 텐서플로와 함께 제공됩니다. 리뷰(단어의 시퀀스(sequence))는 미리 전처리해서 정수 시퀀스로 변환되어 있습니다. 각 정수는 어휘 사전에 있는 특정 단어를 의미합니다.\n",
        "\n",
        "다음 코드는 IMDB 데이터셋을 컴퓨터에 다운로드합니다(또는 이전에 다운로드 받았다면 캐시된 복사본을 사용합니다):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXXx5Oc3pOmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05fd7ea1-92d4-4bd1-c9f4-e24f13b6a471"
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "# load_data(): ordered by freq; Any less frequent word will appear as oov_char value in the sequence data.\n",
        "\n",
        "# you can ignore this warning: VisibleDeprecationWarning https://stackoverflow.com/questions/66414449/importing-imdb-dataset-from-keras-dataset "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odr-KlzO-lkL"
      },
      "source": [
        "매개변수 `num_words=10000`은 훈련 데이터에서 가장 많이 등장하는 상위 10,000개의 단어를 선택합니다. 데이터 크기를 적당하게 유지하기 위해 드물에 등장하는 단어는 제외하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l50X3GfjpU4r"
      },
      "source": [
        "## 데이터 탐색\n",
        "\n",
        "잠시 데이터 형태를 알아 보겠습니다. 이 데이터셋의 샘플은 전처리된 정수 배열입니다. 이 정수는 영화 리뷰에 나오는 단어를 나타냅니다. 레이블(label)은 정수 0 또는 1입니다. 0은 부정적인 리뷰이고 1은 긍정적인 리뷰입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8qCnve_-lkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be332a24-230d-45db-e54d-2eeb9aef9204"
      },
      "source": [
        "print(\"훈련 샘플: {}, 레이블: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플: 25000, 레이블: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnKvHWW4-lkW"
      },
      "source": [
        "리뷰 텍스트는 어휘 사전의 특정 단어를 나타내는 정수로 변환되어 있습니다. 첫 번째 리뷰를 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtTS4kpEpjbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e579af4-ab7d-4254-8b66-c30349f1aff0"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIE4l_72x7DP"
      },
      "source": [
        "영화 리뷰들은 길이가 다릅니다. 다음 코드는 첫 번째 리뷰와 두 번째 리뷰에서 단어의 개수를 출력합니다. 신경망의 입력은 길이가 같아야 하기 때문에 나중에 이 문제를 해결하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-6Ii9Pfx6Nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a4ee51-e04d-4d44-de3a-a5b0ff2f01d9"
      },
      "source": [
        "len(train_data[0]), len(train_data[1]) # 나중에 같게 만듦"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wJg2FiYpuoX"
      },
      "source": [
        "### 정수를 단어로 다시 변환하기\n",
        "\n",
        "정수를 다시 텍스트로 변환하는 방법이 있다면 유용할 것입니다. 여기에서는 정수와 문자열을 매핑한 딕셔너리(dictionary) 객체에 질의하는\u001c 헬퍼(helper) 함수를 만들겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr5s_1alpzop"
      },
      "source": [
        "# 단어와 정수 인덱스를 매핑한 딕셔너리\n",
        "word_index = imdb.get_word_index() # {string: index}; punctuations are not tokenized??\n",
        "# print(word_index[\"this\"], word_index[\"film\"], word_index[\"was\"]) # 11 19 13; 참고로 load_data 했을 때는 이미 14 22 17\n",
        "\n",
        "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} #첫 단어 11 -> 14로\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # to get string in decode_review(); {\"this\": 14} -> {14: \"this\"}\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text]) # get(x, \"default\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3CNRvEZVppl"
      },
      "source": [
        "이제 `decode_review` 함수를 사용해 첫 번째 리뷰 텍스트를 출력할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_OqxmH6-lkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "9efd91f9-89d3-451d-97da-a7e227cb008a"
      },
      "source": [
        "decode_review(train_data[0])\n",
        "# compare with cell 14 -> {14: \"this\"}, {22: \"film\"}\n",
        "# robert <UNK> : Robert Redford's\n",
        "# released for <UNK> : released for retail (not included in the top 10,000 freq. words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFP_XKVRp4_S"
      },
      "source": [
        "## 데이터 준비\n",
        "\n",
        "리뷰-정수 배열-는 신경망에 주입하기 전에 텐서로 변환되어야 합니다. 변환하는 방법에는 몇 가지가 있습니다:\n",
        "\n",
        "* 원-핫 인코딩(one-hot encoding)은 정수 배열을 0과 1로 이루어진 벡터로 변환합니다. 예를 들어 배열 [3, 5]을 인덱스 3과 5만 1이고 나머지는 모두 0인 10,000차원 벡터로 변환할 수 있습니다. 그다음 실수 벡터 데이터를 다룰 수 있는 층-Dense 층-을 신경망의 첫 번째 층으로 사용합니다. 이 방법은 `num_words * num_reviews` 크기의 행렬이 필요하기 때문에 메모리를 많이 사용합니다.\n",
        "* 다른 방법으로는, 정수 배열의 길이가 모두 같도록 패딩(padding)을 추가해 `max_length * num_reviews` 크기의 정수 텐서를 만듭니다. 이런 형태의 텐서를 다룰 수 있는 임베딩(embedding) 층을 신경망의 첫 번째 층으로 사용할 수 있습니다.\n",
        "\n",
        "이 튜토리얼에서는 두 번째 방식을 사용하겠습니다.\n",
        "\n",
        "영화 리뷰의 길이가 같아야 하므로 [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) 함수를 사용해 길이를 맞추겠습니다:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_CQFFnBalOX"
      },
      "source": [
        "> Dense 층: 일반적인 Fully Connected Layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jQv-omsHurp"
      },
      "source": [
        "# 정해준 길이보다 길이가 긴 샘플은 값을 일부 자르고, 정해준 길이보다 길이가 짧은 샘플은 값을 0으로 채움\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO5MBpyQdipD"
      },
      "source": [
        "샘플의 길이를 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USSSBnkE-lky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b601006-1858-430d-b7c9-0f7b2693dbf1"
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJoxZGyfjT5V"
      },
      "source": [
        "(패딩된) 첫 번째 리뷰 내용을 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG8X9cqi-lk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f683d6af-7e00-4bfa-f279-9b23ba5cfbc1"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLC02j2g-llC"
      },
      "source": [
        "## 모델 구성\n",
        "\n",
        "신경망은 층(layer)을 쌓아서 만듭니다. 이 구조에서는 두 가지를 결정해야 합니다:\n",
        "\n",
        "* 모델에서 얼마나 많은 층을 사용할 것인가?\n",
        "* 각 층에서 얼마나 많은 *은닉 유닛*(hidden unit)을 사용할 것인가?\n",
        "\n",
        "이 예제의 입력 데이터는 단어 인덱스의 배열입니다. 예측할 레이블은 0 또는 1입니다. 이 문제에 맞는 모델을 구성해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpKOoWgu-llD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534808d9-c0ab-4214-8314-391c3857ad3e"
      },
      "source": [
        "# 입력 크기는 영화 리뷰 데이터셋에 적용된 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16, input_shape=(None,))) # 2D (10000) -> 3D (16)\n",
        "model.add(keras.layers.GlobalAveragePooling1D()) # 3D(16) ->  2D(16)\n",
        "model.add(keras.layers.Dense(16, activation='relu')) # use_bias=True; 2D(16 + 1 bias) -> 16\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid')) # 2D(16 + 1 bias) -> (1)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PbKQ6mucuKL"
      },
      "source": [
        "층을 순서대로 쌓아 분류기(classifier)를 만듭니다:\n",
        "\n",
        "1. 첫 번째 층은 `Embedding` 층입니다. 이 층은 정수로 인코딩된 단어를 입력 받고 각 단어 인덱스에 해당하는 임베딩 벡터를 찾습니다. 이 벡터는 모델이 훈련되면서 학습됩니다. 이 벡터는 출력 배열에 새로운 차원으로 추가됩니다. 최종 차원은 `(batch, sequence, embedding)`이 됩니다.\n",
        "2. 그다음 `GlobalAveragePooling1D` 층은 `sequence` 차원에 대해 평균을 계산하여 각 샘플에 대해 고정된 길이의 출력 벡터를 반환합니다. 이는 길이가 다른 입력을 다루는 가장 간단한 방법입니다.\n",
        "3. 이 고정 길이의 출력 벡터는 16개의 은닉 유닛을 가진 완전 연결(fully-connected) 층(`Dense`)을 거칩니다.\n",
        "4. 마지막 층은 하나의 출력 노드(node)를 가진 완전 연결 층입니다. `sigmoid` 활성화 함수를 사용하여 0과 1 사이의 실수를 출력합니다. 이 값은 확률 또는 신뢰도를 나타냅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XMwnDOp-llH"
      },
      "source": [
        "### 은닉 유닛\n",
        "\n",
        "위 모델에는 입력과 출력 사이에 두 개의 중간 또는 \"은닉\" 층이 있습니다. 출력(유닛 또는 노드, 뉴런)의 개수는 층이 가진 표현 공간(representational space)의 차원이 됩니다. 다른 말로 하면, 내부 표현을 학습할 때 허용되는 네트워크 자유도의 양입니다.\n",
        "\n",
        "모델에 많은 은닉 유닛(고차원의 표현 공간)과 층이 있다면 네트워크는 더 복잡한 표현을 학습할 수 있습니다. 하지만 네트워크의 계산 비용이 많이 들고 원치않는 패턴을 학습할 수도 있습니다. 이런 표현은 훈련 데이터의 성능을 향상시키지만 테스트 데이터에서는 그렇지 못합니다. 이를 *과대적합*(overfitting)이라고 부릅니다. 나중에 이에 대해 알아 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4EqVWg4-llM"
      },
      "source": [
        "### 손실 함수와 옵티마이저\n",
        "\n",
        "모델이 훈련하려면 손실 함수(loss function)과 옵티마이저(optimizer)가 필요합니다. 이 예제는 이진 분류 문제이고 모델이 확률을 출력하므로(출력층의 유닛이 하나이고 `sigmoid` 활성화 함수를 사용합니다), `binary_crossentropy` 손실 함수를 사용하겠습니다.\n",
        "\n",
        "다른 손실 함수를 선택할 수 없는 것은 아닙니다. 예를 들어 `mean_squared_error`를 선택할 수 있습니다. 하지만 일반적으로 `binary_crossentropy`가 확률을 다루는데 적합합니다. 이 함수는 확률 분포 간의 거리를 측정합니다. 여기에서는 정답인 타깃 분포와 예측 분포 사이의 거리입니다.\n",
        "\n",
        "나중에 회귀(regression) 문제(예를 들어 주택 가격을 예측하는 문제)에 대해 살펴 볼 때 평균 제곱 오차(mean squared error) 손실 함수를 어떻게 사용하는지 알아 보겠습니다.\n",
        "\n",
        "이제 모델이 사용할 옵티마이저와 손실 함수를 설정해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr0GP-cQ-llN"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCWYwkug-llQ"
      },
      "source": [
        "## 검증 세트 만들기\n",
        "\n",
        "모델을 훈련할 때 모델이 만난 적 없는 데이터에서 정확도를 확인하는 것이 좋습니다. 원본 훈련 데이터에서 10,000개의 샘플을 떼어내어 *검증 세트*(validation set)를 만들겠습니다. (왜 테스트 세트를 사용하지 않을까요? 훈련 데이터만을 사용하여 모델을 개발하고 튜닝하는 것이 목표입니다. 그다음 테스트 세트를 사용해서 딱 한 번만 정확도를 평가합니다)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NpcXY9--llS"
      },
      "source": [
        "x_val = train_data[:10000] # first 10000 (out of 25000)\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35jv_fzP-llU"
      },
      "source": [
        "## 모델 훈련\n",
        "\n",
        "이 모델을 512개의 샘플로 이루어진 미니배치(mini-batch)에서 40번의 에포크(epoch) 동안 훈련합니다. `x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 40번 반복한다는 뜻입니다. 훈련하는 동안 10,000개의 검증 세트에서 모델의 손실과 정확도를 모니터링합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXSGrjWZ-llW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e0aa3e-ebf7-4a47-fa95-1c85f17f97d8"
      },
      "source": [
        "results = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)\n",
        "# batch_size=512 (power of 2) -> b/c the number of PP(physical processor) is often a power of 2\n",
        "# validation_data is not trained"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 2s 33ms/step - loss: 0.6927 - accuracy: 0.5141 - val_loss: 0.6904 - val_accuracy: 0.5781\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.6885 - accuracy: 0.6758 - val_loss: 0.6832 - val_accuracy: 0.6043\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.6782 - accuracy: 0.6555 - val_loss: 0.6673 - val_accuracy: 0.7448\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.6581 - accuracy: 0.7645 - val_loss: 0.6418 - val_accuracy: 0.7601\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.6270 - accuracy: 0.7843 - val_loss: 0.6082 - val_accuracy: 0.7727\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.5868 - accuracy: 0.8007 - val_loss: 0.5666 - val_accuracy: 0.8014\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.5404 - accuracy: 0.8237 - val_loss: 0.5241 - val_accuracy: 0.8179\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.4964 - accuracy: 0.8377 - val_loss: 0.4825 - val_accuracy: 0.8325\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.4516 - accuracy: 0.8520 - val_loss: 0.4459 - val_accuracy: 0.8422\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.4077 - accuracy: 0.8707 - val_loss: 0.4150 - val_accuracy: 0.8498\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.3770 - accuracy: 0.8785 - val_loss: 0.3897 - val_accuracy: 0.8578\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.3459 - accuracy: 0.8896 - val_loss: 0.3696 - val_accuracy: 0.8623\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.3240 - accuracy: 0.8936 - val_loss: 0.3533 - val_accuracy: 0.8660\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2987 - accuracy: 0.9012 - val_loss: 0.3398 - val_accuracy: 0.8709\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2821 - accuracy: 0.9058 - val_loss: 0.3294 - val_accuracy: 0.8728\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2731 - accuracy: 0.9062 - val_loss: 0.3205 - val_accuracy: 0.8753\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2543 - accuracy: 0.9128 - val_loss: 0.3128 - val_accuracy: 0.8780\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2430 - accuracy: 0.9176 - val_loss: 0.3070 - val_accuracy: 0.8806\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2291 - accuracy: 0.9207 - val_loss: 0.3018 - val_accuracy: 0.8811\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2167 - accuracy: 0.9278 - val_loss: 0.2975 - val_accuracy: 0.8827\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2072 - accuracy: 0.9302 - val_loss: 0.2941 - val_accuracy: 0.8837\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1992 - accuracy: 0.9320 - val_loss: 0.2915 - val_accuracy: 0.8841\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.1918 - accuracy: 0.9364 - val_loss: 0.2909 - val_accuracy: 0.8835\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1811 - accuracy: 0.9419 - val_loss: 0.2876 - val_accuracy: 0.8853\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1738 - accuracy: 0.9435 - val_loss: 0.2867 - val_accuracy: 0.8849\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1630 - accuracy: 0.9505 - val_loss: 0.2859 - val_accuracy: 0.8844\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1572 - accuracy: 0.9507 - val_loss: 0.2860 - val_accuracy: 0.8847\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1552 - accuracy: 0.9516 - val_loss: 0.2860 - val_accuracy: 0.8854\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1511 - accuracy: 0.9539 - val_loss: 0.2862 - val_accuracy: 0.8868\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1385 - accuracy: 0.9593 - val_loss: 0.2877 - val_accuracy: 0.8857\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1386 - accuracy: 0.9587 - val_loss: 0.2882 - val_accuracy: 0.8867\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.1286 - accuracy: 0.9621 - val_loss: 0.2893 - val_accuracy: 0.8862\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1236 - accuracy: 0.9638 - val_loss: 0.2906 - val_accuracy: 0.8864\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1190 - accuracy: 0.9690 - val_loss: 0.2926 - val_accuracy: 0.8859\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1171 - accuracy: 0.9678 - val_loss: 0.2948 - val_accuracy: 0.8848\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.1131 - accuracy: 0.9696 - val_loss: 0.2984 - val_accuracy: 0.8834\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.1135 - accuracy: 0.9681 - val_loss: 0.2996 - val_accuracy: 0.8831\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1075 - accuracy: 0.9680 - val_loss: 0.3022 - val_accuracy: 0.8840\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0969 - accuracy: 0.9743 - val_loss: 0.3051 - val_accuracy: 0.8839\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0993 - accuracy: 0.9748 - val_loss: 0.3069 - val_accuracy: 0.8830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EEGuDVuzb5r"
      },
      "source": [
        "## 모델 평가\n",
        "\n",
        "모델의 성능을 확인해 보죠. 두 개의 값이 반환됩니다. 손실(오차를 나타내는 숫자이므로 낮을수록 좋습니다)과 정확도입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOMKywn4zReN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee147232-520d-4c59-923e-79e0f0033771"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels, verbose=2)\n",
        "\n",
        "print(results) # [loss value, metrics value]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 - 1s - loss: 0.3280 - accuracy: 0.8742\n",
            "[0.3280160427093506, 0.8741999864578247]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1iEXVTR0Z2t"
      },
      "source": [
        "이 예제는 매우 단순한 방식을 사용하므로 87% 정도의 정확도를 달성했습니다. 고급 방법을 사용한 모델은 95%에 가까운 정확도를 얻습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KggXVeL-llZ"
      },
      "source": [
        "## 정확도와 손실 그래프 그리기\n",
        "\n",
        "`model.fit()`은 `History` 객체를 반환합니다. 여기에는 훈련하는 동안 일어난 모든 정보가 담긴 딕셔너리(dictionary)가 들어 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcvSXvhp-llb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e587b5fa-25e4-4b5c-b409-cd0ed76972ec"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRKsqL40-lle"
      },
      "source": [
        "네 개의 항목이 있습니다. 훈련과 검증 단계에서 모니터링하는 지표들입니다. 훈련 손실과 검증 손실을 그래프로 그려 보고, 훈련 정확도와 검증 정확도도 그래프로 그려서 비교해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGoYf2Js-lle",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4d6edc85-2cfe-40e1-bad0-ea63eb509335"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\"는 \"파란색 점\"입니다\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b는 \"파란 실선\"입니다\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hXx-xOv-llh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b11135d2-1442-4555-c8db-3479457a4a77"
      },
      "source": [
        "plt.clf()   # 그림을 초기화합니다\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFEmZ5zq-llk"
      },
      "source": [
        "이 그래프에서 점선은 훈련 손실과 훈련 정확도를 나타냅니다. 실선은 검증 손실과 검증 정확도입니다.\n",
        "\n",
        "훈련 손실은 에포크마다 *감소*하고 훈련 정확도는 *증가*한다는 것을 주목하세요. 경사 하강법 최적화를 사용할 때 볼 수 있는 현상입니다. 매 반복마다 최적화 대상의 값을 최소화합니다.\n",
        "\n",
        "하지만 검증 손실과 검증 정확도에서는 그렇지 못합니다. 약 20번째 에포크 이후가 최적점인 것 같습니다. 이는 과대적합 때문입니다. 이전에 본 적 없는 데이터보다 훈련 데이터에서 더 잘 동작합니다. 이 지점부터는 모델이 과도하게 최적화되어 테스트 데이터에서 *일반화*되기 어려운 훈련 데이터의 특정 표현을 학습합니다.\n",
        "\n",
        "여기에서는 과대적합을 막기 위해 단순히 20번째 에포크 근처에서 훈련을 멈출 수 있습니다. 나중에 콜백(callback)을 사용하여 자동으로 이렇게 하는 방법을 배워 보겠습니다."
      ]
    }
  ]
}